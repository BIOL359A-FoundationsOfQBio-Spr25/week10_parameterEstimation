{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagheri Lab Tutorial | Parameter Estimation\n",
    "### Augest 05 2025\n",
    "Objectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from scipy.stats import norm, uniform\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "! git clone https://github.com/BIOL359A-FoundationsOfQBio-Spr25/week10_parameterEstimation.git\n",
    "! cp -r week10_parameterEstimation/* .\n",
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sir.sir import SIR_ABM\n",
    "\n",
    "class ParameterEstimator:\n",
    "    \"\"\"Simple parameter estimation methods for SIR ABM\"\"\"\n",
    "    \n",
    "    def __init__(self, observed_data, lattice_size=40):\n",
    "        \"\"\"\n",
    "        observed_data: dict with 'time', 'S', 'I', 'R' arrays\n",
    "        \"\"\"\n",
    "        self.observed_data = observed_data\n",
    "        self.lattice_size = lattice_size\n",
    "        self.results = {}\n",
    "        \n",
    "    def simulate_sir(self, params):\n",
    "        \"\"\"Run SIR simulation with given parameters\"\"\"\n",
    "        Pm, PI, PR = params\n",
    "        \n",
    "        # Bounds check\n",
    "        if any(p < 0 or p > 2 for p in params):\n",
    "            return None\n",
    "            \n",
    "        try:\n",
    "            model = SIR_ABM(\n",
    "                lattice_size=self.lattice_size,\n",
    "                initial_infected_fraction=0.01,\n",
    "                initial_susceptible_fraction=0.49,\n",
    "                Pm=Pm, PI=PI, PR=PR\n",
    "            )\n",
    "            \n",
    "            max_time = max(self.observed_data['time'])\n",
    "            model.run(max_time=max_time, record_interval=0.1)\n",
    "            \n",
    "            return model.history\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def calculate_mse(self, params):\n",
    "        \"\"\"Calculate Mean Squared Error between simulation and observed data\"\"\"\n",
    "        sim_data = self.simulate_sir(params)\n",
    "        if sim_data is None:\n",
    "            return 1e6\n",
    "            \n",
    "        # Interpolate simulation data to match observed time points\n",
    "        obs_times = np.array(self.observed_data['time'])\n",
    "        sim_times = np.array(sim_data['time'])\n",
    "        \n",
    "        if len(sim_times) == 0:\n",
    "            return 1e6\n",
    "            \n",
    "        # Simple linear interpolation for I (infected fraction)\n",
    "        sim_I = np.interp(obs_times, sim_times, sim_data['I'])\n",
    "        obs_I = np.array(self.observed_data['I'])\n",
    "        \n",
    "        mse = np.mean((sim_I - obs_I)**2)\n",
    "        return mse\n",
    "    \n",
    "    def least_squares(self, initial_guess=None):\n",
    "        \"\"\"Least squares parameter estimation\"\"\"\n",
    "        print(\"Running Least Squares estimation...\")\n",
    "        \n",
    "        if initial_guess is None:\n",
    "            initial_guess = [1.0, 0.05, 0.005]\n",
    "            \n",
    "        bounds = [(0.1, 2.0), (0.01, 0.2), (0.001, 0.05)]\n",
    "        \n",
    "        result = minimize(\n",
    "            self.calculate_mse,\n",
    "            initial_guess,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds\n",
    "        )\n",
    "        \n",
    "        self.results['least_squares'] = {\n",
    "            'params': result.x,\n",
    "            'mse': result.fun,\n",
    "            'success': result.success\n",
    "        }\n",
    "        \n",
    "        print(f\"LS Result: Pm={result.x[0]:.3f}, PI={result.x[1]:.4f}, PR={result.x[2]:.4f}, MSE={result.fun:.6f}\")\n",
    "        return result.x, result.fun\n",
    "    \n",
    "    def mle_estimation(self, initial_guess=None):\n",
    "        \"\"\"Maximum Likelihood Estimation (assuming Gaussian errors)\"\"\"\n",
    "        print(\"Running MLE estimation...\")\n",
    "        \n",
    "        def neg_log_likelihood(params):\n",
    "            sim_data = self.simulate_sir(params)\n",
    "            if sim_data is None:\n",
    "                return 1e6\n",
    "                \n",
    "            obs_times = np.array(self.observed_data['time'])\n",
    "            sim_times = np.array(sim_data['time'])\n",
    "            \n",
    "            if len(sim_times) == 0:\n",
    "                return 1e6\n",
    "                \n",
    "            sim_I = np.interp(obs_times, sim_times, sim_data['I'])\n",
    "            obs_I = np.array(self.observed_data['I'])\n",
    "            \n",
    "            # Assume constant variance (could be estimated)\n",
    "            sigma = 0.05\n",
    "            nll = -np.sum(norm.logpdf(obs_I, sim_I, sigma))\n",
    "            return nll\n",
    "        \n",
    "        if initial_guess is None:\n",
    "            initial_guess = [1.0, 0.05, 0.005]\n",
    "            \n",
    "        bounds = [(0.1, 2.0), (0.01, 0.2), (0.001, 0.05)]\n",
    "        \n",
    "        result = minimize(\n",
    "            neg_log_likelihood,\n",
    "            initial_guess,\n",
    "            method='L-BFGS-B',\n",
    "            bounds=bounds\n",
    "        )\n",
    "        \n",
    "        mse = self.calculate_mse(result.x)\n",
    "        \n",
    "        self.results['mle'] = {\n",
    "            'params': result.x,\n",
    "            'nll': result.fun,\n",
    "            'mse': mse,\n",
    "            'success': result.success\n",
    "        }\n",
    "        \n",
    "        print(f\"MLE Result: Pm={result.x[0]:.3f}, PI={result.x[1]:.4f}, PR={result.x[2]:.4f}, MSE={mse:.6f}\")\n",
    "        return result.x, result.fun\n",
    "    \n",
    "    def bayesian_mcmc(self, n_samples=1000, burn_in=200):\n",
    "        \"\"\"Simple Bayesian estimation using Metropolis-Hastings\"\"\"\n",
    "        print(f\"Running Bayesian MCMC ({n_samples} samples)...\")\n",
    "        \n",
    "        # Prior distributions (uniform)\n",
    "        def log_prior(params):\n",
    "            Pm, PI, PR = params\n",
    "            if 0.1 <= Pm <= 2.0 and 0.01 <= PI <= 0.2 and 0.001 <= PR <= 0.05:\n",
    "                return 0.0  # log(1) for uniform prior\n",
    "            return -np.inf\n",
    "        \n",
    "        def log_likelihood(params):\n",
    "            sim_data = self.simulate_sir(params)\n",
    "            if sim_data is None:\n",
    "                return -np.inf\n",
    "                \n",
    "            obs_times = np.array(self.observed_data['time'])\n",
    "            sim_times = np.array(sim_data['time'])\n",
    "            \n",
    "            if len(sim_times) == 0:\n",
    "                return -np.inf\n",
    "                \n",
    "            sim_I = np.interp(obs_times, sim_times, sim_data['I'])\n",
    "            obs_I = np.array(self.observed_data['I'])\n",
    "            \n",
    "            sigma = 0.05\n",
    "            return np.sum(norm.logpdf(obs_I, sim_I, sigma))\n",
    "        \n",
    "        # Initialize chain\n",
    "        current_params = np.array([1.0, 0.05, 0.005])\n",
    "        current_ll = log_likelihood(current_params)\n",
    "        \n",
    "        samples = []\n",
    "        accepted = 0\n",
    "        \n",
    "        # Proposal covariance\n",
    "        prop_cov = np.diag([0.1, 0.01, 0.001])**2\n",
    "        \n",
    "        for i in range(n_samples + burn_in):\n",
    "            # Propose new parameters\n",
    "            proposal = np.random.multivariate_normal(current_params, prop_cov)\n",
    "            \n",
    "            # Calculate acceptance probability\n",
    "            prior_ratio = log_prior(proposal) - log_prior(current_params)\n",
    "            if prior_ratio == -np.inf:\n",
    "                continue\n",
    "                \n",
    "            prop_ll = log_likelihood(proposal)\n",
    "            ll_ratio = prop_ll - current_ll\n",
    "            \n",
    "            alpha = min(0, prior_ratio + ll_ratio)\n",
    "            \n",
    "            if np.log(np.random.random()) < alpha:\n",
    "                current_params = proposal\n",
    "                current_ll = prop_ll\n",
    "                accepted += 1\n",
    "            \n",
    "            if i >= burn_in:\n",
    "                samples.append(current_params.copy())\n",
    "            \n",
    "            if (i + 1) % 200 == 0:\n",
    "                acc_rate = accepted / (i + 1)\n",
    "                print(f\"  Iteration {i+1}, acceptance rate: {acc_rate:.3f}\")\n",
    "        \n",
    "        samples = np.array(samples)\n",
    "        \n",
    "        # Calculate posterior means\n",
    "        posterior_means = np.mean(samples, axis=0)\n",
    "        posterior_stds = np.std(samples, axis=0)\n",
    "        mse = self.calculate_mse(posterior_means)\n",
    "        \n",
    "        self.results['bayesian'] = {\n",
    "            'params': posterior_means,\n",
    "            'std': posterior_stds,\n",
    "            'samples': samples,\n",
    "            'mse': mse,\n",
    "            'acceptance_rate': accepted / (n_samples + burn_in)\n",
    "        }\n",
    "        \n",
    "        print(f\"Bayesian Result: Pm={posterior_means[0]:.3f}±{posterior_stds[0]:.3f}, \"\n",
    "              f\"PI={posterior_means[1]:.4f}±{posterior_stds[1]:.4f}, \"\n",
    "              f\"PR={posterior_means[2]:.4f}±{posterior_stds[2]:.4f}, MSE={mse:.6f}\")\n",
    "        \n",
    "        return posterior_means, samples\n",
    "    \n",
    "    def abc_estimation(self, n_samples=500, tolerance=0.01):\n",
    "        \"\"\"Approximate Bayesian Computation\"\"\"\n",
    "        print(f\"Running ABC estimation ({n_samples} samples, tolerance={tolerance})...\")\n",
    "        \n",
    "        accepted_params = []\n",
    "        n_attempts = 0\n",
    "        max_attempts = n_samples * 50  # Prevent infinite loops\n",
    "        \n",
    "        while len(accepted_params) < n_samples and n_attempts < max_attempts:\n",
    "            n_attempts += 1\n",
    "            \n",
    "            # Sample from prior\n",
    "            Pm = np.random.uniform(0.1, 2.0)\n",
    "            PI = np.random.uniform(0.01, 0.2)\n",
    "            PR = np.random.uniform(0.001, 0.05)\n",
    "            params = [Pm, PI, PR]\n",
    "            \n",
    "            # Calculate distance\n",
    "            mse = self.calculate_mse(params)\n",
    "            \n",
    "            if mse < tolerance:\n",
    "                accepted_params.append(params)\n",
    "            \n",
    "            if (n_attempts % 1000) == 0:\n",
    "                print(f\"  Attempted {n_attempts}, accepted {len(accepted_params)}\")\n",
    "        \n",
    "        if len(accepted_params) == 0:\n",
    "            print(\"No parameters accepted! Try increasing tolerance.\")\n",
    "            return None, None\n",
    "        \n",
    "        accepted_params = np.array(accepted_params)\n",
    "        posterior_means = np.mean(accepted_params, axis=0)\n",
    "        posterior_stds = np.std(accepted_params, axis=0)\n",
    "        mse = self.calculate_mse(posterior_means)\n",
    "        \n",
    "        self.results['abc'] = {\n",
    "            'params': posterior_means,\n",
    "            'std': posterior_stds,\n",
    "            'samples': accepted_params,\n",
    "            'mse': mse,\n",
    "            'acceptance_rate': len(accepted_params) / n_attempts,\n",
    "            'tolerance': tolerance\n",
    "        }\n",
    "        \n",
    "        print(f\"ABC Result: Pm={posterior_means[0]:.3f}±{posterior_stds[0]:.3f}, \"\n",
    "              f\"PI={posterior_means[1]:.4f}±{posterior_stds[1]:.4f}, \"\n",
    "              f\"PR={posterior_means[2]:.4f}±{posterior_stds[2]:.4f}, MSE={mse:.6f}\")\n",
    "        \n",
    "        return posterior_means, accepted_params\n",
    "\n",
    "def generate_synthetic_data(true_params=[1.2, 0.08, 0.01], noise_level=0.02, lattice_size=40):\n",
    "    \"\"\"Generate synthetic observed data\"\"\"\n",
    "    print(\"Generating synthetic observed data...\")\n",
    "    \n",
    "    Pm, PI, PR = true_params\n",
    "    model = SIR_ABM(\n",
    "        lattice_size=lattice_size,\n",
    "        initial_infected_fraction=0.01,\n",
    "        initial_susceptible_fraction=0.49,\n",
    "        Pm=Pm, PI=PI, PR=PR\n",
    "    )\n",
    "    \n",
    "    model.run(max_time=3.0, record_interval=0.1)\n",
    "    \n",
    "    # Add noise to infected fraction\n",
    "    times = np.array(model.history['time'])\n",
    "    I_clean = np.array(model.history['I'])\n",
    "    I_noisy = I_clean + np.random.normal(0, noise_level, len(I_clean))\n",
    "    I_noisy = np.clip(I_noisy, 0, 1)  # Keep in [0,1]\n",
    "    \n",
    "    observed_data = {\n",
    "        'time': times,\n",
    "        'S': np.array(model.history['S']),\n",
    "        'I': I_noisy,\n",
    "        'R': np.array(model.history['R'])\n",
    "    }\n",
    "    \n",
    "    print(f\"Generated data with {len(times)} time points\")\n",
    "    return observed_data, true_params\n",
    "\n",
    "def compare_all_methods(observed_data, lattice_size=40):\n",
    "    \"\"\"Run all estimation methods and compare results\"\"\"\n",
    "    estimator = ParameterEstimator(observed_data, lattice_size)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"PARAMETER ESTIMATION COMPARISON\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Run all methods\n",
    "    estimator.least_squares()\n",
    "    print()\n",
    "    \n",
    "    estimator.mle_estimation()\n",
    "    print()\n",
    "    \n",
    "    estimator.bayesian_mcmc(n_samples=800, burn_in=200)\n",
    "    print()\n",
    "    \n",
    "    estimator.abc_estimation(n_samples=300, tolerance=0.015)\n",
    "    print()\n",
    "    \n",
    "    return estimator\n",
    "\n",
    "def plot_results(estimator, true_params=None):\n",
    "    \"\"\"Plot comparison of results\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Plot 1: Parameter estimates\n",
    "    methods = []\n",
    "    param_estimates = []\n",
    "    param_errors = []\n",
    "    \n",
    "    for method, result in estimator.results.items():\n",
    "        methods.append(method.replace('_', ' ').title())\n",
    "        param_estimates.append(result['params'])\n",
    "        if 'std' in result:\n",
    "            param_errors.append(result['std'])\n",
    "        else:\n",
    "            param_errors.append([0, 0, 0])\n",
    "    \n",
    "    param_estimates = np.array(param_estimates)\n",
    "    param_errors = np.array(param_errors)\n",
    "    \n",
    "    x = np.arange(len(methods))\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[0,0].bar(x - width, param_estimates[:, 0], width, yerr=param_errors[:, 0], \n",
    "                  label='Pm', alpha=0.8, capsize=5)\n",
    "    axes[0,0].bar(x, param_estimates[:, 1]*10, width, yerr=param_errors[:, 1]*10, \n",
    "                  label='PI×10', alpha=0.8, capsize=5)\n",
    "    axes[0,0].bar(x + width, param_estimates[:, 2]*100, width, yerr=param_errors[:, 2]*100, \n",
    "                  label='PR×100', alpha=0.8, capsize=5)\n",
    "    \n",
    "    if true_params:\n",
    "        axes[0,0].axhline(true_params[0], color='red', linestyle='--', alpha=0.7, label='True Pm')\n",
    "        axes[0,0].axhline(true_params[1]*10, color='green', linestyle='--', alpha=0.7, label='True PI×10')\n",
    "        axes[0,0].axhline(true_params[2]*100, color='blue', linestyle='--', alpha=0.7, label='True PR×100')\n",
    "    \n",
    "    axes[0,0].set_xlabel('Method')\n",
    "    axes[0,0].set_ylabel('Parameter Value')\n",
    "    axes[0,0].set_title('Parameter Estimates Comparison')\n",
    "    axes[0,0].set_xticks(x)\n",
    "    axes[0,0].set_xticklabels(methods, rotation=45)\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: MSE comparison\n",
    "    mse_values = [result['mse'] for result in estimator.results.values()]\n",
    "    axes[0,1].bar(methods, mse_values, alpha=0.8, color='orange')\n",
    "    axes[0,1].set_xlabel('Method')\n",
    "    axes[0,1].set_ylabel('Mean Squared Error')\n",
    "    axes[0,1].set_title('Model Fit Quality (MSE)')\n",
    "    axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Fit visualization\n",
    "    obs_times = estimator.observed_data['time']\n",
    "    obs_I = estimator.observed_data['I']\n",
    "    \n",
    "    axes[1,0].plot(obs_times, obs_I, 'ko-', label='Observed', markersize=4)\n",
    "    \n",
    "    colors = ['red', 'blue', 'green', 'purple']\n",
    "    for i, (method, result) in enumerate(estimator.results.items()):\n",
    "        sim_data = estimator.simulate_sir(result['params'])\n",
    "        if sim_data:\n",
    "            sim_times = np.array(sim_data['time'])\n",
    "            sim_I = np.array(sim_data['I'])\n",
    "            axes[1,0].plot(sim_times, sim_I, color=colors[i%len(colors)], \n",
    "                          label=f\"{method.replace('_', ' ').title()}\", alpha=0.8)\n",
    "    \n",
    "    axes[1,0].set_xlabel('Time')\n",
    "    axes[1,0].set_ylabel('Infected Fraction')\n",
    "    axes[1,0].set_title('Model Fits')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Posterior distributions (if available)\n",
    "    if 'bayesian' in estimator.results and 'samples' in estimator.results['bayesian']:\n",
    "        samples = estimator.results['bayesian']['samples']\n",
    "        axes[1,1].hist(samples[:, 1], bins=30, alpha=0.7, label='PI (Bayesian)', density=True)\n",
    "        axes[1,1].axvline(samples[:, 1].mean(), color='red', linestyle='--', label='Mean')\n",
    "        if true_params:\n",
    "            axes[1,1].axvline(true_params[1], color='green', linestyle='--', label='True')\n",
    "        axes[1,1].set_xlabel('PI Parameter')\n",
    "        axes[1,1].set_ylabel('Density')\n",
    "        axes[1,1].set_title('Posterior Distribution (PI)')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1,1].text(0.5, 0.5, 'No posterior\\nsamples available', \n",
    "                      transform=axes[1,1].transAxes, ha='center', va='center')\n",
    "        axes[1,1].set_title('Posterior Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def create_summary_table(estimator, true_params=None):\n",
    "    \"\"\"Create a summary table of results\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for method, result in estimator.results.items():\n",
    "        row = {\n",
    "            'Method': method.replace('_', ' ').title(),\n",
    "            'Pm': f\"{result['params'][0]:.3f}\",\n",
    "            'PI': f\"{result['params'][1]:.4f}\",\n",
    "            'PR': f\"{result['params'][2]:.4f}\",\n",
    "            'MSE': f\"{result['mse']:.6f}\"\n",
    "        }\n",
    "        \n",
    "        if 'std' in result:\n",
    "            row['Pm'] += f\" ± {result['std'][0]:.3f}\"\n",
    "            row['PI'] += f\" ± {result['std'][1]:.4f}\"\n",
    "            row['PR'] += f\" ± {result['std'][2]:.4f}\"\n",
    "        \n",
    "        if 'acceptance_rate' in result:\n",
    "            row['Accept Rate'] = f\"{result['acceptance_rate']:.3f}\"\n",
    "        \n",
    "        data.append(row)\n",
    "    \n",
    "    if true_params:\n",
    "        data.append({\n",
    "            'Method': 'TRUE VALUES',\n",
    "            'Pm': f\"{true_params[0]:.3f}\",\n",
    "            'PI': f\"{true_params[1]:.4f}\",\n",
    "            'PR': f\"{true_params[2]:.4f}\",\n",
    "            'MSE': 'N/A'\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Example usage function\n",
    "def run_comparison_example():\n",
    "    \"\"\"Run a complete comparison example\"\"\"\n",
    "    print(\"SIMPLE SIR PARAMETER ESTIMATION COMPARISON\")\n",
    "    print(\"==========================================\")\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    true_params = [1.2, 0.08, 0.01]  # Pm, PI, PR\n",
    "    observed_data, _ = generate_synthetic_data(true_params, noise_level=0.02)\n",
    "    \n",
    "    # Run comparison\n",
    "    estimator = compare_all_methods(observed_data)\n",
    "    \n",
    "    # Show results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY TABLE\")\n",
    "    print(\"=\"*60)\n",
    "    summary = create_summary_table(estimator, true_params)\n",
    "    print(summary.to_string(index=False))\n",
    "    \n",
    "    # Plot results\n",
    "    plot_results(estimator, true_params)\n",
    "    \n",
    "    return estimator, observed_data, true_params\n",
    "\n",
    "# Quick test functions\n",
    "def quick_test_ls(observed_data):\n",
    "    \"\"\"Quick least squares test\"\"\"\n",
    "    estimator = ParameterEstimator(observed_data)\n",
    "    return estimator.least_squares()\n",
    "\n",
    "def quick_test_mle(observed_data):\n",
    "    \"\"\"Quick MLE test\"\"\"\n",
    "    estimator = ParameterEstimator(observed_data)\n",
    "    return estimator.mle_estimation()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the complete example\n",
    "    estimator, data, true_params = run_comparison_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
